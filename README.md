# LexiFlow - AI-Powered English Learning Application

LexiFlow is a hybrid vocabulary + AI conversation learning application built with modern technologies. It combines manual vocabulary collection with natural AI conversation practice, where AI intelligently suggests new vocabulary based on conversation analysis.

## ğŸ“¦ Project Structure

This repository contains two separate implementations:

- **`/web-apps/frontend/`** - Webç‰ˆ (Phase 1 MVP) - Next.js browser-based application
- **`/frontend/`** - Tauriç‰ˆ (Desktop App) - Tauri desktop application (planned)
- **`/backend/`** - Rust API Server (Phase 2) - Axum backend for future migration

### Why Two Separate Implementations?

The Webç‰ˆ and Tauriç‰ˆ are kept separate due to fundamental differences in capabilities:

| Feature             | Webç‰ˆ (`/web-apps/frontend/`) | Tauriç‰ˆ (`/frontend/`)   |
| ------------------- | ----------------------------- | ------------------------ |
| **Cache Strategy**  | Server-side (Vercel KV/Redis) | Local (SQLite/IndexedDB) |
| **Cache Sharing**   | âœ… Shared across users        | âŒ Per-user only         |
| **API Cost**        | ğŸ’° Lower (shared cache)       | ğŸ’° Higher (no sharing)   |
| **Offline Mode**    | âŒ Limited                    | âœ… Full support          |
| **Native Features** | âŒ Browser restricted         | âœ… Full OS integration   |
| **Deployment**      | Vercel/Cloud                  | App Store/Direct         |

**Key Design Decision**: Server-side caching in Webç‰ˆ allows multiple users to share API response caches, significantly reducing Gemini API costs. Tauriç‰ˆ requires local-only caching, resulting in higher API usage per user.

See individual README files for detailed implementation strategies:

- [Webç‰ˆ README](./web-apps/frontend/README.md)
- [Tauriç‰ˆ README](./frontend/README.md)

## ğŸš€ Features

### Core Functionality

- âœ… **Manual Vocabulary Collection**: Rich metadata (definitions, phonetics, examples, translations)
- âœ… **AI Conversation Practice**: Free-form natural dialogue with AI (B2 English level)
- âœ… **AI Vocabulary Suggestions**: AI analyzes conversations and suggests relevant vocabulary
- âœ… **Post-Conversation Review**: Swipeable card interface for vocabulary collection
- âœ… **Mid-Conversation Help**: Ask vocabulary questions during conversation (tutor mode)
- âœ… **Conversation Analytics**: Topic progression, skills assessment, linguistic analysis

### Vocabulary Management

- **Rich Word Metadata**: Part of speech, phonetic symbols, example sentences, Japanese translation
- **Category Organization**: Organize words by custom categories
- **Real-time Search**: Search across words, meanings, and translations
- **CRUD Operations**: Full create, read, update, delete functionality

### AI Conversation Features

- **Natural Dialogue**: Free-form conversation practice (not vocabulary-focused)
- **Voice Input/Output**: Web Speech API for speaking and listening
- **Dual Input Modes**: Voice or text input during conversation
- **Vocabulary Detection**: AI suggests words based on conversation gaps
- **Contextual Learning**: Words presented with conversation context

### Analytics & Progress Tracking

- **Conversation Sessions**: Track duration, topics, and complexity
- **Skills Assessment**: Grammar accuracy, vocabulary appropriateness, fluency scores
- **Linguistic Analysis**: Sentence complexity, vocabulary level metrics
- **Learning Progress**: Visualize improvement over time

## ğŸ›  Technology Stack

### Phase 1 MVP (Current - Webç‰ˆ)

**Frontend:**

- **Framework**: Next.js 15.4.6 (App Router) with TypeScript 5+
- **Styling**: Tailwind CSS 4+ with Shadcn/ui components
- **State Management**: React Query (TanStack Query)
- **Form Handling**: React Hook Form with Zod validation
- **UI Components**: Radix UI primitives

**Backend:**

- **API**: Next.js API Routes (serverless)
- **Database**: Neon PostgreSQL (serverless)
- **ORM**: Prisma 6+
- **Authentication**: Auth.js (Next-Auth 5.0) with JWT
- **AI Provider**: Gemini API (gemini-2.5-flash-lite)
- **Caching**: In-memory cache â†’ Vercel KV (production)

**Voice Features:**

- **Speech Recognition**: Web Speech API (browser-native)
- **Text-to-Speech**: Web Speech API

**Deployment:**

- **Frontend**: Vercel
- **Database**: Neon (managed PostgreSQL)

### Phase 2 (Planned - Rust Backend Migration)

**Backend:**

- **Language**: Rust
- **Framework**: Axum + Diesel
- **Database**: Same Neon PostgreSQL (no migration needed)
- **Authentication**: JWT (compatible with Auth.js tokens)
- **Deployment**: Shuttle.rs or similar

**Migration Strategy:**

- OpenAPI-first design for clean API contracts
- Frontend changes only `NEXT_PUBLIC_API_URL` environment variable
- Gradual endpoint migration (conversation API first)
- Same database, different API layer

## ğŸ“ Project Structure

```
LexiFlow/
â”œâ”€â”€ web-apps/
â”‚   â””â”€â”€ frontend/                # Webç‰ˆ (Phase 1 MVP - Active Development)
â”‚       â”œâ”€â”€ src/
â”‚       â”‚   â”œâ”€â”€ app/            # Next.js App Router
â”‚       â”‚   â”‚   â”œâ”€â”€ (auth)/     # Authentication routes (login, signup)
â”‚       â”‚   â”‚   â”œâ”€â”€ (main)/     # Main app routes
â”‚       â”‚   â”‚   â”‚   â”œâ”€â”€ page.tsx           # Home (word list)
â”‚       â”‚   â”‚   â”‚   â”œâ”€â”€ add/               # Add new word
â”‚       â”‚   â”‚   â”‚   â”œâ”€â”€ conversation/      # AI conversation
â”‚       â”‚   â”‚   â”‚   â”œâ”€â”€ quiz/              # Review/quiz
â”‚       â”‚   â”‚   â”‚   â””â”€â”€ test/              # Test pages
â”‚       â”‚   â”‚   â””â”€â”€ api/        # Next.js API Routes
â”‚       â”‚   â”‚       â”œâ”€â”€ words/
â”‚       â”‚   â”‚       â”œâ”€â”€ conversation/
â”‚       â”‚   â”‚       â”‚   â”œâ”€â”€ session/       # Session management
â”‚       â”‚   â”‚       â”‚   â”œâ”€â”€ chat/          # AI chat endpoint
â”‚       â”‚   â”‚       â”‚   â”œâ”€â”€ analyze/       # Conversation analysis
â”‚       â”‚   â”‚       â”‚   â””â”€â”€ suggestions/   # Vocabulary suggestions
â”‚       â”‚   â”‚       â””â”€â”€ suggestion-word/
â”‚       â”‚   â”œâ”€â”€ features/       # Feature-based modules
â”‚       â”‚   â”‚   â”œâ”€â”€ vocabulary/
â”‚       â”‚   â”‚   â”‚   â”œâ”€â”€ components/
â”‚       â”‚   â”‚   â”‚   â”œâ”€â”€ lib/
â”‚       â”‚   â”‚   â”‚   â””â”€â”€ types/
â”‚       â”‚   â”‚   â”œâ”€â”€ conversation/
â”‚       â”‚   â”‚   â”‚   â”œâ”€â”€ components/
â”‚       â”‚   â”‚   â”‚   â”œâ”€â”€ lib/
â”‚       â”‚   â”‚   â”‚   â””â”€â”€ types/
â”‚       â”‚   â”‚   â””â”€â”€ suggestions/
â”‚       â”‚   â”œâ”€â”€ components/     # Shared UI components
â”‚       â”‚   â”‚   â””â”€â”€ ui/         # Shadcn/ui components
â”‚       â”‚   â”œâ”€â”€ lib/            # Shared utilities
â”‚       â”‚   â”œâ”€â”€ hooks/          # Custom React hooks
â”‚       â”‚   â”œâ”€â”€ types/          # Global TypeScript types
â”‚       â”‚   â””â”€â”€ constants/
â”‚       â”œâ”€â”€ prisma/
â”‚       â”‚   â”œâ”€â”€ schema.prisma   # Database schema (8 tables)
â”‚       â”‚   â””â”€â”€ migrations/
â”‚       â”œâ”€â”€ auth.config.ts      # Auth.js configuration
â”‚       â”œâ”€â”€ package.json
â”‚       â””â”€â”€ README.md           # Webç‰ˆ documentation
â”‚
â”œâ”€â”€ frontend/                    # Tauriç‰ˆ (Desktop App - Planned)
â”‚   â”œâ”€â”€ src/                    # React frontend (shares components with Webç‰ˆ)
â”‚   â”œâ”€â”€ src-tauri/              # Rust backend (Tauri commands)
â”‚   â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”‚   â”œâ”€â”€ commands/       # Tauri commands
â”‚   â”‚   â”‚   â”œâ”€â”€ cache/          # Local SQLite cache
â”‚   â”‚   â”‚   â””â”€â”€ services/
â”‚   â”‚   â””â”€â”€ Cargo.toml
â”‚   â””â”€â”€ README.md               # Tauriç‰ˆ documentation
â”‚
â”œâ”€â”€ backend/                     # Rust API Server (Phase 2 - Planned)
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ routes/             # Axum routes
â”‚   â”‚   â”œâ”€â”€ models/             # Diesel models
â”‚   â”‚   â”œâ”€â”€ handlers/
â”‚   â”‚   â””â”€â”€ services/
â”‚   â”œâ”€â”€ migrations/             # Diesel migrations
â”‚   â””â”€â”€ Cargo.toml
â”‚
â”œâ”€â”€ CLAUDE.md                    # Detailed requirements & architecture
â””â”€â”€ README.md                    # This file
```

### Database Schema (8 Tables)

**Core Tables:**

- `users` - User management
- `words` - Vocabulary collection with rich metadata
- `categories` - Vocabulary categories

**AI Conversation Analytics Tables:**

- `conversation_sessions` - Conversation session tracking
- `conversation_topics` - Topic progression tracking
- `linguistic_analysis` - Linguistic complexity metrics
- `skills_assessments` - Grammar, vocabulary, fluency scores
- `vocabulary_suggestions` - Contextual word suggestions with conversation context

## ğŸš¦ Getting Started (Webç‰ˆ - Phase 1 MVP)

### Prerequisites

- **Node.js** 18+ and npm
- **Neon PostgreSQL** account (free tier available)
- **Gemini API** key (free tier available)
- **Git** for version control

### Quick Start

1. **Clone the repository:**

```bash
git clone https://github.com/yourusername/LexiFlow.git
cd LexiFlow/web-apps/frontend
```

2. **Install dependencies:**

```bash
npm install
```

3. **Set up environment variables:**

Create `.env.local` file:

```bash
# Database (Neon PostgreSQL)
DATABASE_URL="your-neon-database-url"

# Authentication
AUTH_SECRET="your-random-secret-key"
AUTH_URL="http://localhost:3000"

# AI Provider
GEMINI_API_KEY="your-gemini-api-key"

# App Configuration
NEXT_PUBLIC_APP_NAME="LexiFlow"
```

4. **Initialize database:**

```bash
npx prisma generate
npx prisma db push
```

5. **Start development server:**

```bash
npm run dev
```

The application will be available at `http://localhost:3000`

### Development Commands

```bash
npm run dev          # Start dev server with Turbopack
npm run build        # Production build
npm run start        # Start production server
npm run lint         # Run ESLint
npm run format       # Format with Prettier
npm run generate     # Generate Prisma Client + build
```

For detailed setup instructions, see [Webç‰ˆ README](./web-apps/frontend/README.md)

## ğŸ”§ Configuration

### Environment Variables (Webç‰ˆ)

**Required:**

```bash
# Database
DATABASE_URL="postgresql://..."              # Neon PostgreSQL connection string

# Authentication
AUTH_SECRET="random-secret-key"              # Generate with: openssl rand -base64 32
AUTH_URL="http://localhost:3000"             # Your app URL

# AI Provider
GEMINI_API_KEY="your-gemini-api-key"        # Get from Google AI Studio
```

**Optional:**

```bash
# App Configuration
NEXT_PUBLIC_APP_NAME="LexiFlow"
NEXT_PUBLIC_API_URL="http://localhost:3000" # For Phase 2 Rust backend

# Caching (Production)
KV_URL="redis://..."                         # Vercel KV for production caching
KV_REST_API_URL="https://..."
KV_REST_API_TOKEN="..."
```

## ğŸ“¡ API Endpoints

### Vocabulary Management

```
GET    /api/words               # List user's vocabulary
POST   /api/words               # Add new word
GET    /api/words/:id           # Get specific word
PUT    /api/words/:id           # Update word
DELETE /api/words/:id           # Delete word
```

### AI Vocabulary Suggestions

```
POST   /api/suggestion-word/gemini  # Get AI vocabulary recommendations
                                     # (Uses intelligent caching)
```

### Conversation Management

```
POST   /api/conversation/session              # Create new session
GET    /api/conversation/session              # Get recent sessions
PUT    /api/conversation/session/:id          # End session
GET    /api/conversation/session/:id          # Get session details
```

### AI Chat

```
POST   /api/conversation/chat                 # Send message, get AI response
                                              # (Context-aware, B2 level)
```

### Conversation Analysis

```
POST   /api/conversation/analyze              # Analyze conversation
                                              # Returns: topics, skills, suggestions
GET    /api/conversation/suggestions/:id     # Get session suggestions
PUT    /api/conversation/suggestions/:id     # Update suggestion status
```

### Authentication

```
POST   /api/auth/signin                       # Sign in
POST   /api/auth/signup                       # Sign up
POST   /api/auth/signout                      # Sign out
GET    /api/auth/session                      # Get current session
```

## ğŸ—„ Database Schema (8 Tables)

### Core Tables

**users**

- User authentication and profile management

**words**

- Vocabulary collection with rich metadata
- Fields: word, meaning, translation, category, part_of_speech, phonetic, example
- Foreign key: userId

**categories**

- Custom vocabulary categories per user
- Foreign key: userId

### AI Conversation Analytics Tables

**conversation_sessions**

- Track conversation sessions with start/end timestamps
- Foreign key: userId

**conversation_topics**

- Topic progression during conversations
- Fields: topic, order_sequence, complexity_level
- Foreign key: sessionId

**linguistic_analysis**

- Linguistic complexity metrics per session
- Fields: avg_sentence_length, vocabulary_level, grammar_complexity
- Foreign key: sessionId

**skills_assessments**

- Skills evaluation per session
- Fields: grammar_accuracy_score, vocabulary_appropriateness_score,
  sentence_complexity_score, flow_smoothness_score,
  response_timing_avg, natural_phrase_usage_score
- Foreign key: sessionId

**vocabulary_suggestions**

- AI-suggested vocabulary with conversation context
- Fields: suggested_word, user_word_used, conversation_context,
  suggestion_reason, status (pending/accepted/dismissed)
- Foreign key: sessionId

See [Prisma Schema](./web-apps/frontend/prisma/schema.prisma) for complete definitions.

## ğŸ— Development

### Adding New Features

1. **Backend Changes**:
   - Add new models in `src/models/`
   - Create handlers in `src/handlers/`
   - Update routes in `src/main.rs`
   - Add migrations if needed

2. **Frontend Changes**:
   - Add new pages in `src/app/`
   - Create components in `src/components/`
   - Update API client in `src/lib/api.ts`
   - Add TypeScript types in `src/types/`

### Code Quality

- **Rust**: Use `cargo fmt` and `cargo clippy` for code formatting and linting
- **TypeScript**: Use `npm run lint` and `npm run type-check`
- **Database**: Always create migrations for schema changes

## ğŸš€ Deployment

### Backend (Shuttle.rs)

```bash
cd backend
cargo shuttle deploy
```

### Frontend (Vercel)

```bash
cd frontend
vercel deploy
```

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ“ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ™ Acknowledgments

- Built with modern web technologies and best practices
- Powered by Google Gemini API for intelligent conversation practice
- Inspired by the need for natural, context-driven vocabulary learning
- Leverages Next.js for optimal user experience
- Future Rust backend for performance and type safety

## ğŸ“ Support

For support, please open an issue in the GitHub repository or contact the development team.

---

---

**LexiFlow** - Learn English naturally through AI conversation! ğŸŒŸ

**Current Status**: Phase 1 MVP (Webç‰ˆ) - Active Development âœ…
**Next Steps**: Conversation analytics visualization, mid-conversation vocabulary mode
